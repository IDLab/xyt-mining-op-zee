{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecteren parameters DBScan\n",
    "Met dit script testen we welke parameters alleen de stoplocaties clusteren met als doel dat de computer straks zelf de juiste parameters kan selecteren.  \n",
    "\n",
    "Om dit te testen, bouwen we een for loop die meerdere malen de DBScan uitvoert met verschillende combinaties van de parameters epsilon en minimal samples. \n",
    "\n",
    "Om te zicht te krijgen in welke combinatie van epsilon en minimal samples leidt tot groot verschil in distributie tussen clusters en ruis, geven we elke combinatie van parameters een u-score (Mann-Withney U). Waarbij een lage u-score staat voor veel verschil in distributie en een hoge u-score staat voor minder verschil in distributie. Maar let op: de parameters met de laagste u-score betekend niet dat er alleen stoplocaties zijn geclusterd.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laat packages\n",
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "from scipy.stats import mannwhitneyu\n",
    "from sklearn.cluster import DBSCAN\n",
    "from geopy.distance import great_circle\n",
    "from shapely.geometry import MultiPoint\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laat de pre-processed data\n",
    "df = pd.read_csv(\"sample_AIS_preprocessing.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Selecteer features DBScan\n",
    "Features zijn de waarden die wij meegeven als input aan de DBScan. Wij geven latitude/ longitude mee ter bepaling van de locatie en die punten te clusteren die dicht bij elkaar liggen. Snelheid geven mee om die punten te clusteren die vergelijkbare snelheid hebben of in het geval van stoplocaties een lage snelheid hebben. \n",
    "\n",
    "Naast de bovenstaande features willen verschillende features testen. Namelijk volgnummer vs. volgnummer met tijdselement en koersstabiliteit. Het meenemen van volgnummer zorgt ervoor dat zichtbaar wordt hoevaak iemand op dezelfde locatie geweest is. Het geeft een rangorde aan de punten, waardoor er onderscheidt gemaakt wordt tussen punten die dichtbij elkaar liggen qua afstand en snelheid, maar wel verschillen in tijd. Een afweging is of je alleen rangorde (bijv. 1,2,3,4,5) wil meegeven, of dat je daaraan nog een extra tijdselement (bijv. 1 ,40, 60, 180) aan toe wil voegen. In dit geval, berekenen je het verschil in seconden tussen twee punten. Daarnaast kun je koersstabiliteit meegeven. Naar verwachting is dat de koersstabiliteit verschilt tussen clusters en ruis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features worden aan de DBScan gegeven in vorm van een array. De waarden worden genormaliseerd door de functie scale. De waarden variëeren nu tussen -5 en 5. \n",
    "## Features die je kunt meenemen zijn: t_latitude (latitude), t_longitude (longitude), t_speed (speed), VgNr (volgnummer met tijdselement), ID (volgnummer zonder tijdselement), angle_deg_diff(koersstabiliteit: eerste afgeleide van hoek tussen twee punten in graden 0-180)\n",
    "coords_speed = np.asarray(df[[\"t_latitude\", \"t_longitude\", \"t_speed\", \"VgNr\"]])\n",
    "coords = preprocessing.scale(coords_speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creëer functie die per parameter combinatie aangeeft wat de u-waarden zijn.\n",
    "def gemiddelde_kmu_per_eps(df, coords, eps, min_samples, speed_column=\"t_speed\"):\n",
    "    # Hier run je de DBScan\n",
    "    model = DBSCAN(eps=eps, min_samples=min_samples, algorithm=\"auto\").fit(coords)\n",
    "    # Cluster labels opvragen\n",
    "    cluster_labels = model.labels_\n",
    "    # Aantal clusters\n",
    "    num_clusters = len(set(cluster_labels))\n",
    "    # clusters labels naar kolom\n",
    "    df[\"cluster\"] = cluster_labels\n",
    "    \n",
    "    # selecteer snelheidskolom van clusters en berekenen gemiddelde snelheid en aantal punten in cluster \n",
    "    clusters = df.t_speed[df[\"cluster\"] > -1]\n",
    "    # Berekenen gemiddelde snelheid en tel het aantal punten in de cluster kolom\n",
    "    mean_kmu_cluster = clusters.mean()\n",
    "    count_cluster = clusters.count()\n",
    "    \n",
    "    #  selecteer snelheidskolom van ruis en berekenen gemiddelde snelheid en aantal punten \n",
    "    ruis = df.t_speed[df[\"cluster\"] == -1]\n",
    "    # Berekenen gemiddelde snelheid en tel aantal punten in de ruis kolom\n",
    "    mean_kmu_ruis = ruis.mean()\n",
    "    count_ruis = ruis.count()\n",
    "\n",
    "    # Verschil snelheidskolom van cluster vs ruis in u waarden\n",
    "    u, prob = mannwhitneyu(clusters, ruis)\n",
    "    \n",
    "    return(eps, min_samples, num_clusters, count_cluster, mean_kmu_cluster, count_ruis, mean_kmu_ruis, u, prob)\n",
    "\n",
    "# Bovenstaande functie uitvoeren voor 100 verschillende epsilons en 45 verschillende MinPoints combinaties\n",
    "output_list = []\n",
    "for epsilon in np.linspace(1e-4, 1, num=100):\n",
    "    for min_samples in range(2, 45, 1):\n",
    "        # Hier roep je functie aan\n",
    "        output = gemiddelde_kmu_per_eps(df=df, coords=coords, eps=epsilon, min_samples=min_samples)\n",
    "        output_list.append(output)\n",
    "\n",
    "# Output functie naar dataframe en csv (nu hoef je functie maar 1x te runnen)\n",
    "output_df = pd.DataFrame(output_list, columns = [\"eps\", \"min_samples\", \"N_cluster\", \"count_cluster\", \"mean_kmu_cluster\", \"count_ruis\", \"mean_kmu_ruis\", \"u\", \"prob\"])\n",
    "output_df.to_csv(\"sample_output.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
