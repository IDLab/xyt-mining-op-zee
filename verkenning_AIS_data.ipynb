{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verkenning stoplocaties AIS data\n",
    "\n",
    "Met dit script identificeren we stoplocaties op zee met behulp van AIS data. \n",
    "\n",
    "\n",
    "### AIS data\n",
    "\n",
    "Samenvattend bevat AIS data gegevens over de identiteit, positie, snelheid en koers van schepen. De volgende gegevens worden verzonden:\n",
    "    AIS transmitters send data every 2 to 10 seconds while underway and every 3\n",
    "    minutes while at anchor. The main AIS data field are:\n",
    "        - MMSI (Maritime Mobile Service Identity) – a series of nine digits\n",
    "          uniquely identifying ship stations;\n",
    "        - Navigation status – “at anchor”, “under way using engine(s)”, or “not\n",
    "          under command”;\n",
    "        - Rate of turn – right or left, 0 to 720 degrees per minute;\n",
    "        - Speed over ground – 0 to 102 knots with 0.1 knot resolution;\n",
    "        - Position accuracy;\n",
    "        - Longitude and Latitude – to 1/10,000 minute;\n",
    "        - Course over ground – relative to true north to 0.1 degree;\n",
    "        - True Heading – 0 to 359 degrees from gyro compass;\n",
    "        - Timestamp – Coordinated Universal Time (UTC) time accurate to nearest\n",
    "          second when this data was generated.\n",
    "     \n",
    "     Moreover, every 6 minutes the AIS transmitter sends additional fields,\n",
    "     including:\n",
    "         - IMO (International Maritime Organization) ship identification number\n",
    "         - a seven digit number that remains unchanged upon transfer of the\n",
    "           ship's registration to another Country;\n",
    "         - International radio call sign – up to seven characters, assigned to\n",
    "           the vessel by its Country of registry;\n",
    "         - Vessel Name – 20 characters to represent the name of the vessel;\n",
    "         - Type of ship/cargo;\n",
    "         - Dimensions of ship – to nearest meter;\n",
    "         - Type of positioning system – such as GPS, Differential Global\n",
    "           Positioning Systems (DGPS) or Long Range Navigation (LORAN)-C;\n",
    "         - Location of positioning system's antenna on-board the vessel;\n",
    "         - Draught of ship – 0.1 meter to 25.5 meters;\n",
    "         - Destination – max 20 characters;\n",
    "         - Estimated time of arrival (ETA) at destination – UTC date hour:\n",
    "           minute.\n",
    "\n",
    "Bron: https://www.sciencedirect.com/science/article/pii/S2405535216300201\n",
    "\n",
    "De reporting interval verhoogd als de snelheid van een schip verhoogd:\n",
    "    - Position report:\n",
    "        - 3 min: at anchor\n",
    "        - 10 sec: < 14 knopen\n",
    "        - 6 sec: < 23 knopen\n",
    "    - Standard Class B equipment position report:\n",
    "        - 3 min: < 2 knots\n",
    "        - 30 sec: < 14 knots\n",
    "        - 15 sec: < 23 knots\n",
    "\n",
    "Bron: https://www.sciencedirect.com/science/article/pii/S0308597X17305535\n",
    "\n",
    "Overige artikelen:\n",
    "https://www.sciencedirect.com/science/article/pii/S0888613X13000728\n",
    "\n",
    "\n",
    "### Stoplocaties vinden met DBScan\n",
    "\n",
    "We zullen stoplocaties identificeren aan de hand van een model die het ID-Lab heeft gecreëerd om stoplocaties te vinden van taxichauffers(pitch 19.0002: Verkenning GPS data van taxi’s). Kort samengevat, identificeerd het model stoplocaties aan de geografische/ tijdsgegevens. Deze gegevens worden ingevoerd in de DBScan, die de bewegende en niet-bewegende punten clustert. Dit doet de DBScan aan de hand van een aangegeven epsilon en minimale aantal punten binnen de epsilon. Deze parameters worden in het model gekozen aan de hand van de Mann Withney-U test. Dan kiezen we die parameters, die de hoogste U waarde heeft op basis van gemiddelde snelheid. Dit houdt in: hoe hoger de u-waarde, hoe groter het verschil in snelheid tussen bewegende (ruis) en niet-bewegende punten (clusters).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aan de slag met AIS data van 1 schip\n",
    "\n",
    "Het doel van deze opdracht is het identificeren van stoplocaties van schepen uit AIS data. Om goed zicht te hebben op wat we doen, analyseren we eerst data van 1 schip. We hebben een schip gekozen die veel te vinden is in de ankervakken. Dit zijn de schepen: \n",
    "    - Schip met MMSI 477050500 en IMO 248532000 \n",
    "    - Schip met MMSI: 9605243 IMO 9417261 \n",
    "\n",
    "Daarnaast is er een schip die actief vaart in de eerste miljoen rijen:\n",
    "    - Schip met MMSI: 205370590\n",
    "\n",
    "\n",
    "### Verkenning AIS data\n",
    "\n",
    "Als eerst verkennen we de data door de coordinaten op een kaart te plotten en een visualiseren van de descriptive statistics. \n",
    "\n",
    "##### Stap 1: Importeer packages en data\n",
    "Gezien het CSV bestand meer dan 500 miljoen rijen bevat, daarom itereren we door de rijen en verwijderen we alle rijen van andere schepen. Binnen de DAT-omgeving kunnen totaal 2 miljoen rijen worden opgeslagen via deze methode, daarna stopt de kernel wegens te veel RAM gebruik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import of different libraries\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('bmh')\n",
    "\n",
    "import matplotlib.lines as mlines\n",
    "from shapely.geometry import Polygon #Module for manipulation and analysis of geometric objects in the Cartesian plane.\n",
    "import pandas as pd #This module provides high-performance, easy-to-use data structures and data analysis tools for Python\n",
    "from shapely.geometry import Point #The Point constructor takes positional coordinate values or point tuple parameters to create a single point.\n",
    "import numpy as np\n",
    "from geopy import distance\n",
    "import csv\n",
    "import tqdm\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "import datetime\n",
    "import fnmatch\n",
    "import concurrent.futures\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import NullFormatter\n",
    "import mpld3\n",
    "import folium\n",
    "from geopy.distance import geodesic\n",
    "import seaborn as sns\n",
    "\n",
    "###-----------------------------------------------------------------------------------------------\n",
    "### HIERONDER DE METHODE OM DATA IN TE LEZEN. GEZIEN DEZE METHODE ERG LANG DUURT, HEB IK EEN NIEUWE CSV GEMAAKT. \n",
    "\n",
    "# with open(\"AIS_week.csv\", newline='') as csvfile:\n",
    "#     csvreader = csv.reader(csvfile);\n",
    "#     header = next(csvreader);\n",
    "#     data = {}\n",
    "#     for h in header:\n",
    "#         data[h] = []\n",
    "#     for index, row in enumerate(csvreader):\n",
    "# #         if index == 10000:\n",
    "# #             break;\n",
    "#         if row[5] == \"477050500\":\n",
    "#             for h, v in zip(header, row):\n",
    "#                 data[h].append(v);\n",
    "                \n",
    "# d = pd.DataFrame(data)\n",
    "# d.to_csv(\"raw_MMSI_477050500.csv\")\n",
    "###---------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Inlezen van csv (hierboven gecreëerd)\n",
    "df_raw = pd.read_csv(\"raw_MMSI_477050500.csv\")\n",
    "\n",
    "# Selecteren van de juiste kolommen\n",
    "    # cols = list(df.columns.values)\n",
    "df = df_raw[['t_starttime',\n",
    "             't_updatetime',\n",
    "             't_duration',\n",
    "             't_mmsi',\n",
    "             't_name',\n",
    "             't_latitude',\n",
    "             't_longitude',\n",
    "             't_orientation',\n",
    "             't_length',\n",
    "             't_breadth',\n",
    "             't_sensors',\n",
    "             't_navstatus',\n",
    "             't_imo',\n",
    "             't_speed',\n",
    "             't_heading',\n",
    "             'p_destination',\n",
    "             'p_draught',\n",
    "             'p_antposfront',\n",
    "             'p_antposleft',\n",
    "             'p_shiptype',\n",
    "             'p_cargotype']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stap 2: Plot coordinaten op kaart (Folium)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Zoek het middelste punt en zet de coordinaten in een lijst\n",
    "mid_location = df['t_latitude'].mean(), df['t_longitude'].mean()\n",
    "coords = df[[\"t_latitude\", \"t_longitude\"]].values.tolist()\n",
    "labels = df[\"t_name\"].values.tolist()\n",
    "\n",
    "# Creëer een folium map met de coordinaten\n",
    "m = folium.Map(location=mid_location, zoom_start=8)\n",
    "for point in range(len(coords)):\n",
    "    popup = folium.Popup(labels[point], parse_html=True)\n",
    "    folium.Marker(coords[point], popup=popup).add_to(m)\n",
    "\n",
    "# Sla kaart op als HTML \n",
    "m.save('all_points_map_mmsi_477050500.html')\n",
    "\n",
    "# Weergeef de kaart (functie doet het niet op de DAT-omgeving)\n",
    "    #display(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stap 1: omzetten van tijd en toevoegen van tijdskolommen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Omzetten van UTC tijd naar locale tijd (Amsterdam) en verwijderen overbodige kolommen\n",
    "df[\"Time\"] = pd.DatetimeIndex(df['t_updatetime']).time\n",
    "df['Date'] = pd.DatetimeIndex(df['t_updatetime']).date\n",
    "df['DateTime_UTC'] = df.apply(lambda r : pd.datetime.combine(r['Date'],r['Time']),1)\n",
    "df['DateTime_Local'] = df['DateTime_UTC'].dt.tz_localize('utc').dt.tz_convert('Europe/Amsterdam')\n",
    "del df['DateTime_UTC']\n",
    "del df['Time']\n",
    "del df['Date']\n",
    "\n",
    "# splitten tijdgegevens in kolommen\n",
    "df['Date'] = pd.DatetimeIndex(df['DateTime_Local']).date\n",
    "df['Time'] = pd.DatetimeIndex(df['DateTime_Local']).time\n",
    "df['DateTime'] = df[\"DateTime_Local\"]\n",
    "\n",
    "## Hieronder nog meer code om tijd op te splitten\n",
    "df['Year'] = pd.DatetimeIndex(df['DateTime']).year\n",
    "df['Month'] = pd.DatetimeIndex(df['DateTime']).month\n",
    "df['Day'] = pd.DatetimeIndex(df['DateTime']).day\n",
    "df['Weeknr'] = pd.DatetimeIndex(df['DateTime']).week\n",
    "df['Weekdag'] = pd.DatetimeIndex(df['DateTime']).weekday\n",
    "df['Hour'] = pd.DatetimeIndex(df['DateTime']).hour\n",
    "df[\"minute\"] = pd.DatetimeIndex(df[\"DateTime\"]).minute\n",
    "df[\"sec\"] = pd.DatetimeIndex(df[\"DateTime\"]).second\n",
    "\n",
    "# Bereken datum in seconden\n",
    "Year_sec = df[\"Year\"] * 365 * 24 * 60 * 60\n",
    "Month_sec = df[\"Month\"] * 31 * 24 * 60 * 60\n",
    "Day_sec = df[\"Day\"] * 24 * 60 * 60\n",
    "Hour_sec = df[\"Hour\"] * 60 * 60\n",
    "min_sec = df[\"minute\"] * 60\n",
    "sec_sec = df[\"sec\"]\n",
    "\n",
    "\n",
    "df[\"date_in_sec\"] = Year_sec + Month_sec + Day_sec + Hour_sec + min_sec + sec_sec\n",
    "\n",
    "#Verwijderen kolommen \n",
    "del df['DateTime_Local']\n",
    "# del df[\"Dt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stap 2: Afstand bereken tussen twee XY Punten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nieuwe kolom (van a naar b) --> drop na \n",
    "df[\"Lat_b\"] = df[\"t_latitude\"].shift(-1)\n",
    "df[\"Lon_b\"] = df[\"t_longitude\"].shift(-1)\n",
    "df = df.dropna()\n",
    "\n",
    "## Bereken afstand (van a naar b)\n",
    "def distancer_km(row):\n",
    "    coords_1 = (row['t_latitude'], row[\"t_longitude\"])\n",
    "    coords_2 = (row['Lat_b'], row['Lon_b'])\n",
    "    return geodesic(coords_1, coords_2).km\n",
    "    #return vincenty(coords_1, coords_2).km\n",
    "\n",
    "def distancer_m(row):\n",
    "    coords_1 = (row['t_latitude'], row['t_longitude'])\n",
    "    coords_2 = (row['Lat_b'], row['Lon_b'])\n",
    "    return geodesic(coords_1, coords_2).m\n",
    "    #return vincenty(coords_1, coords_2).km\n",
    "\n",
    "df['distance_km'] = df.apply(distancer_km, axis=1)\n",
    "df['distance_m'] = df.apply(distancer_m, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stap 3:  Bereken tijd tussen twee XY punten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##verschil in seconden tussen twee XY punten\n",
    "df[\"date_b\"] = df[\"DateTime\"]\n",
    "df[\"date_b\"] = df[\"date_b\"].shift(-1)\n",
    "df = df.dropna(subset = [\"DateTime\", \"date_b\"]).reset_index(drop=True)\n",
    "# df[\"date_b\"] = df[\"date_b\"].dropna()\n",
    "df[\"diff\"] = df[\"date_b\"] - df[\"DateTime\"]\n",
    "df[\"diff_sec\"] = df[\"diff\"].astype('timedelta64[s]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stap 4: Bereken snelheid tussen twee XY Punten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## meters per seconde / km per uur\n",
    "df[\"speed_ms\"] = df[\"distance_m\"]/df[\"diff_sec\"]\n",
    "df[\"speed_kmu\"] = df[\"distance_km\"]/df[\"diff_sec\"].divide(60*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stap 5: Voeg tijdscomponent toe in volgnummer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creer volgnummer met tijdselement\n",
    "df[\"VgNr\"] = df[\"diff_sec\"].cumsum().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stap 6: Bereken aantal berichten per minuut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aantal berichten per minuut\n",
    "count_messages_per_minute = df.groupby([\"Date\", \"minute\"])[\"t_mmsi\"].count().reset_index(name=\"messages_per_minute\")\n",
    "df_2 = pd.merge(df, count_messages_per_minute, left_on=[\"Date\", \"minute\"], right_on=[\"Date\", \"minute\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stap 7: Sla pre-processed data op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Maak csv preprocessing\n",
    "df_2.to_csv(\"AIS_preprocessing.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap dag vs tijd vs snelheid\n",
    "x_snelheid_tijd = np.array(df[\"Time\"])\n",
    "y_snelheid_tijd = np.array(df[\"Date\"])\n",
    "z_snelheid_tijd = np.array(df[\"t_speed\"])\n",
    "results = pd.DataFrame.from_dict(np.array([x_snelheid_tijd,y_snelheid_tijd,z_snelheid_tijd]).T)\n",
    "results.columns = ['x_snelheid_tijd','y_snelheid_tijd','z_snelheid_tijd']\n",
    "pivotted = results.pivot('y_snelheid_tijd','x_snelheid_tijd','z_snelheid_tijd')\n",
    "\n",
    "pivotted\n",
    "\n",
    "sns.set()\n",
    "pivotted.fillna(value=np.nan, inplace=True)\n",
    "\n",
    "sns.heatmap(pivotted, cmap=\"RdBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lijngrafiek datum vs snelheid vs navigatiestatus\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.lineplot(x=\"DateTime\", y=\"t_speed\", hue=\"t_navstatus\", data=df)\n",
    "\n",
    "## Navigatiestatussen\n",
    "# 0 = under way using engine\n",
    "# 1 = at anchor\n",
    "# 2 = not under command \n",
    "# 3 = restricted maneuverability\n",
    "# 4 = constrained by her draught\n",
    "# 5 = moored\n",
    "# 6 = aground \n",
    "# 7 = engaged in fishing\n",
    "# 8 = under way sailing\n",
    "# 9 = reserved for future amendment of navigational status for ships carrying DG, HS, or MP, or IMO hazard or pollutant category C, high-speed craft (HSC)\n",
    "# 10 = reserved for future amendment of navigational status for ships carrying dangerous goods (DG), harmful substances (HS) or marine pollutants (MP), or IMO hazard or pollutant category A, wing in ground (WIG)\n",
    "# 11 = power-driven vessel towing astern (regional use)\n",
    "# 12 = power-driven vessel pushing ahead or towing alongside (regional use)\n",
    "# 13 = reserved for future use\n",
    "# 14 = AIS-SART (active), MOB-AIS, EPIRB-AIS\n",
    "# 15 = undefined = default (also used by AIS-SART, MOB-AIS and EPIRB-AIS under test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interactieve plot (datum vs snelheid) met Bokeh\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "\n",
    "output_file(\"line.html\")\n",
    "\n",
    "p = figure(plot_width=1000, plot_height=1000)\n",
    "\n",
    "# add a line renderer\n",
    "p.line(df[\"DateTime\"], df[\"t_speed\"], line_width=2)\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap dag vs tijd vs snelheid\n",
    "x_tijd_messages = np.array(df_2[\"Date\"])\n",
    "y_tijd_messages = np.array(df_2[\"Time\"])\n",
    "z_tijd_messages = np.array(df_2[\"messages_per_minute\"])\n",
    "results_tijd_message = pd.DataFrame.from_dict(np.array([x_tijd_messages, y_tijd_messages, z_tijd_messages]).T)\n",
    "results_tijd_message.columns = ['x_tijd_messages', 'y_tijd_messages', 'z_tijd_messages']\n",
    "pivotted_tijd_message = results_tijd_message.pivot('x_tijd_messages', 'y_tijd_messages', 'z_tijd_messages')\n",
    "sns.set()\n",
    "pivotted_tijd_message.fillna(value=np.nan, inplace=True)\n",
    "sns.heatmap(pivotted_tijd_message, cmap=\"RdBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lijngrafiek datum vs snelheid vs navigatiestatus\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.lineplot(x=\"DateTime\", y=\"messages_per_minute\", hue=\"t_navstatus\", data=df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interactieve plot (datum vs snelheid) met Bokeh\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "\n",
    "output_file(\"line_messages_tijd.html\")\n",
    "\n",
    "p = figure(plot_width=1000, plot_height=1000)\n",
    "\n",
    "# add a line renderer\n",
    "p.line(df_2[\"DateTime\"], df_2[\"messages_per_minute\"], line_width=2)\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lijngrafiek datum vs snelheid vs navigatiestatus\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.lineplot(x=\"messages_per_minute\", y=\"t_speed\", data=df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot speed vs messages per minute\n",
    "y = df_2[\"t_speed\"]\n",
    "x = df_2[\"messages_per_minute\"]\n",
    "\n",
    "ax = sns.kdeplot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lijngrafiek messages per minuut vs orientation\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.lineplot(x=\"messages_per_minute\", y=\"t_orientation\", data=df_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecteren van parameters voor DBScan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stap 1: inladen packages en data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "from scipy.stats import mannwhitneyu\n",
    "from sklearn.cluster import DBSCAN\n",
    "from geopy.distance import great_circle\n",
    "from shapely.geometry import MultiPoint\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"AIS_preprocessing.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stap 2: Selecteren van variablen\n",
    "\n",
    "In het algoritme van DBScan kun je variablen selecteren die de clusters gaan vormen. In deze opdracht zijn dat de lat/ lon, de snelheid en VgNr van een XY punt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Schalen van XYV punten \n",
    "coords_speed = np.asarray(df[['t_latitude', 't_longitude', \"t_speed\"]])\n",
    "coords = preprocessing.scale(coords_speed)\n",
    "\n",
    "coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functie maken om tabel te creëren met resultaten DBScan, u waarden en gemiddelde snelheden\n",
    "def gemiddelde_kmu_per_eps(df, coords, eps, min_samples, speed_column=\"t_speed\"):\n",
    "    model = DBSCAN(eps=eps, min_samples=min_samples, algorithm=\"auto\").fit(coords)\n",
    "    cluster_labels = model.labels_\n",
    "    num_clusters = len(set(cluster_labels))\n",
    "    df[\"cluster\"] = cluster_labels\n",
    "    #selecteer snelheidskolom van clusters \n",
    "    clusters = df.t_speed[df[\"cluster\"] > -1]\n",
    "    #selecteer snelheidskolom van ruis\n",
    "    ruis =df.t_speed[df[\"cluster\"] == -1]\n",
    "    #Verschil snelheidskolom van cluster vs ruis in u waarden\n",
    "    u, prob = mannwhitneyu(clusters, ruis)\n",
    "    kmu_per_cluster = df.groupby('cluster')[\"t_speed\"].mean().reset_index(name='kmu_per_cluster')\n",
    "    mean_kmu = kmu_per_cluster[\"kmu_per_cluster\"].mean()\n",
    "    return (eps, min_samples, num_clusters, mean_kmu, u)\n",
    "\n",
    "# Bovenstaande functie uitvoeren voor 500 verschillende epsilons en 7 verschillende MinPoints\n",
    "output_list = []\n",
    "for epsilon in np.linspace(0.001, 0.05, 500):\n",
    "    for min_samples in range(2, 20, 2):\n",
    "        output = gemiddelde_kmu_per_eps(df=df, coords=coords, eps=epsilon, min_samples=min_samples)\n",
    "        output_list.append(output)\n",
    "\n",
    "# Resultaten functie naar tabel\n",
    "output_df = pd.DataFrame(output_list, columns = [\"eps\", \"min_samples\", \"NoP_cluster\", \"mean_kmu_speed\", \"MannWhitney_U\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creëer heatmap om zo de juiste parameters te kunnen selecteren. \n",
    "x = np.array(output_df[\"eps\"])\n",
    "y = np.array(output_df[\"min_samples\"])\n",
    "z = np.array(output_df[\"MannWhitney_U\"])\n",
    "results = pd.DataFrame.from_dict(np.array([x,y,z]).T)\n",
    "results.columns = ['x','y','z']\n",
    "pivotted = results.pivot('y','x','z')\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "sns.heatmap(pivotted, cmap=\"RdBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print per MinPoints de EPS met de hoogste u waarde\n",
    "\n",
    "indices = results.groupby('y')['z'].idxmax; indices\n",
    "u_waarden = results.loc[indices]\n",
    "u_waarden[\"y\"] = u_waarden[\"y\"].astype(int)\n",
    "\n",
    "print(u_waarden)\n",
    "\n",
    "\n",
    "# results.to_csv(\"result_find_eps.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import average_precision_score \n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "#Variabelen invoeren DBScan en schalen\n",
    "df = pd.read_csv(\"AIS_preprocessing.csv\")\n",
    "coords_speed = np.asarray(df[['t_latitude', 't_longitude', \"t_speed\"]])\n",
    "coords = preprocessing.scale(coords_speed)\n",
    "eps_samples = u_waarden[[\"x\", \"y\"]]\n",
    "\n",
    "def dbs(df, coords, eps, min_samples):\n",
    "    model = DBSCAN(eps=eps, min_samples=min_samples, algorithm=\"auto\").fit(coords)\n",
    "    cluster_labels = model.labels_\n",
    "    num_clusters = len(set(cluster_labels))\n",
    "    df[\"cluster\"] = cluster_labels\n",
    "    \n",
    "    ##Bereken gemiddelde snelheid van het cluster\n",
    "    kmu_per_cluster = df.groupby('cluster')['t_speed'].mean().reset_index(name='kmu_per_cluster')\n",
    "    df = pd.merge(df, kmu_per_cluster, on=[\"cluster\"], how=\"right\")\n",
    "\n",
    "    stoplocation = []\n",
    "    for stop in df[\"kmu_per_cluster\"]:\n",
    "        if stop < 2:\n",
    "            stoplocation.append(1)\n",
    "        else:\n",
    "            stoplocation.append(0)\n",
    "\n",
    "    df[\"stoplocation\"] = stoplocation\n",
    "    \n",
    "    #Voeg kolom toe die aangeeft wat een mogelijke stoplocatie is via navigatiestatus\n",
    "    nav_stops = []\n",
    "    for nav in df[\"t_navstatus\"]:\n",
    "        if nav == 1:\n",
    "            nav_stops.append(1)\n",
    "        else:\n",
    "            nav_stops.append(0)\n",
    "\n",
    "    df[\"nav_stops\"] = nav_stops\n",
    "\n",
    "    #precision van clusteren\n",
    "    y_true = df[\"nav_stops\"]\n",
    "    y_pred = df[\"stoplocation\"]\n",
    "    \n",
    "    #checken of de average=\"binary\" de juiste methode is (sklearn)\n",
    "    precision = precision_score(y_true, y_pred, average='binary')\n",
    "    recall = recall_score(y_true, y_pred, average=\"binary\")\n",
    "    count_nav = pd.value_counts(df['nav_stops'].values, sort=False)\n",
    "    count_stop = pd.value_counts(df['stoplocation'].values, sort=False)  \n",
    "    return (eps, min_samples, num_clusters, precision, recall, count_nav, count_stop)\n",
    "\n",
    "#Voer dbscan uit + precision voor elke hoogste u waarden per min_samples\n",
    "output_list_eps = []\n",
    "for index, row in eps_samples.iterrows():\n",
    "    output_eps = dbs(df=df, coords=coords, eps=row[\"x\"], min_samples=row[\"y\"])\n",
    "    output_list_eps.append(output_eps)\n",
    "\n",
    "# Uitkomst in dataframe + print dataframa\n",
    "output_list_eps_df = pd.DataFrame(output_list_eps, columns = [\"eps\", \"min_samples\", \"aantal_cluster\", \"percision\", \"recall\", \"count_nav\", \"count_stop\"])\n",
    "output_list_eps_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster tabel maken\n",
    "In deze stap zullen we de DBScan uitvoeren. Daarna zullen we de cluster verfijnen aan de hand van post-processing. In dit proces zullen we clusters die overlappen in tijd veranderen naar unieke clusters. Gezien binnen de tijden van 1 stoplocatie, niet een andere stoplocatie kan beginnen. Deze stoplocaties zijn uniek (Zie bokeh plot voor verdere uitleg). Daarna selecteren we van elk cluster het middelste XY punt. Aan dit XY Punt, kunnen we data linken zoals streetview foto's, CBS data, lijst met bedrijven, etc. Ook maken we voor de middelste XY punten een cluster tabel, zodat er een overzicht is per luster wat de gemiddelde snelheid is en het aantal punten per cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN\n",
    "from geopy.distance import great_circle\n",
    "from shapely.geometry import MultiPoint\n",
    "from sklearn import preprocessing\n",
    "# from bokeh.plotting import figure, show, output_file\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.io import push_notebook, show, output_notebook, curdoc, show\n",
    "from bokeh.models import ColumnDataSource, Plot, LinearAxis, Grid\n",
    "from bokeh.models.glyphs import VBar\n",
    "output_notebook()\n",
    "\n",
    "df = pd.read_csv(\"AIS_preprocessing.csv\")\n",
    "df_old = df #Nodig voor merge verderop in script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stap 1: voer DBScan uit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variabelen invoeren DBScan en schalen\n",
    "coords_speed = np.asarray(df[['t_latitude', 't_longitude', \"t_speed\"]])\n",
    "coords = preprocessing.scale(coords_speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecteer beste parameters uit vorige stap (heatmap/ lijst beste parameters - U waarden)\n",
    "# Uit de test hierboven blijkt epsilon 0.04 en min_samples 10 tot de juiste resultaten te leiden\n",
    "epsilon = 0.043617\n",
    "min_samples = 10\n",
    "\n",
    "# run DBScan \n",
    "db = DBSCAN(eps=epsilon, min_samples=min_samples, algorithm='auto').fit(coords)\n",
    "cluster_labels = db.labels_\n",
    "num_clusters = len(set(cluster_labels))\n",
    "print('Number of clusters: {}'.format(num_clusters))\n",
    "\n",
    "#Clusterlabels naar column in df\n",
    "df[\"cluster\"] = cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge met de oude gegevens \n",
    "df = df[[\"VgNr\", \"cluster\"]]\n",
    "df_new = pd.merge(df_old, df, on=\"VgNr\", how=\"left\")\n",
    "\n",
    "# Opslaan raw data\n",
    "df_new.to_csv(\"AIS_cluster_raw_eps0006_MinSamples2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stap 2: Post-processing op clustervolgorde\n",
    "In deze stap zorgen we ervoor dat de clusters alleen punten bevat die qua volgorde in tijd overeenkomen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maken van copy van df_total en sorteren op kolom clusters en tijd\n",
    "Add_clusters = df_new.copy()\n",
    "Add_clusters.sort_values(['VgNr'])\n",
    "Add_clusters.head()\n",
    "\n",
    "#Vinden van verschillen in kolom cluster_x\n",
    "Add_clusters[\"Check_overlap\"] = Add_clusters['cluster_x'].diff()\n",
    "#Clusters nieuwe clusterwaarden geven als er een verschil is met vorige rij in kolom Check_overlap.\n",
    "#Let op nieuwe clusternummers komen niet overeen met de oude clusternummers!\n",
    "Add_clusters['Cluster_new']= (Add_clusters['Check_overlap'] != 0).astype(int).cumsum()\n",
    "\n",
    "# De oorspronkelijke cluster -1 (=ruis) overnemen als None waarden in kolom Cluster_new\n",
    "Add_clusters['Cluster_new'] = np.where(Add_clusters['cluster_x'] == -1, -1, (Add_clusters['Cluster_new']))\n",
    "\n",
    "# Verwerken van de modelresultaten tot nieuwe clusters\n",
    "result_total = Add_clusters.sort_values(['Cluster_new'])\n",
    "\n",
    "df_vgnr = result_total.groupby('Cluster_new')['VgNr'].agg(['min','max']).rename(columns={'min': 'vgnr_min', 'max': 'vgnr_max'}).reset_index()\n",
    "df_dt = result_total.groupby('Cluster_new')['DateTime'].agg(['min','max']).rename(columns={'min': 'dt_min', 'max': 'dt_max'}).reset_index()\n",
    "df_concat = pd.merge(df_dt, df_vgnr, left_on='Cluster_new', right_on='Cluster_new')\n",
    "Add_clusters[\"start\"] = Add_clusters.DateTime.isin(df_concat.dt_min).astype(int)\n",
    "Add_clusters[\"end\"] = Add_clusters.DateTime.isin(df_concat.dt_max).astype(int)\n",
    "Add_clusters[\"start\"] = Add_clusters['start'].replace(0, np.nan)\n",
    "Add_clusters[\"end\"] = Add_clusters['end'].replace(0, np.nan)\n",
    "Add_clusters.sort_values(['DateTime'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot clusters op kaart\n",
    "\n",
    "# Zoek het middelste punt en zet de coordinaten in een lijst\n",
    "mid_location = Add_clusters['t_latitude'].mean(), Add_clusters['t_longitude'].mean()\n",
    "coords = Add_clusters[[\"t_latitude\", \"t_longitude\"]].values.tolist()\n",
    "labels = Add_clusters[\"Cluster_new\"].values.tolist()\n",
    "\n",
    "# Creëer een folium map met de coordinaten\n",
    "m = folium.Map(location=mid_location, zoom_start=8)\n",
    "for point in range(len(coords)):\n",
    "    popup = folium.Popup(labels[point], parse_html=True)\n",
    "    folium.Marker(coords[point], popup=popup).add_to(m)\n",
    "\n",
    "# Sla kaart op als HTML \n",
    "m.save('VgNr_mmsi_477050500.html')\n",
    "\n",
    "# Weergeef de kaart (functie doet het niet op de DAT-omgeving)\n",
    "    #display(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sla clusters op\n",
    "Add_clusters.to_csv(\"raw_clusters.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stap 3: zoek middelste punt van cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Maak een array van lat/ lon en clusterslabels\n",
    "coords_new = np.asarray(Add_clusters[['t_latitude', 't_longitude']])\n",
    "cluster_array = np.asarray(Add_clusters[\"Cluster_new\"])\n",
    "num_cluster_array = len(set(cluster_array))\n",
    "num_cluster_array_2 = 530\n",
    "clusters = pd.Series([coords_new[cluster_array == n] for n in range(num_cluster_array_2)])\n",
    "clusters = clusters[clusters.astype(str) != '[]']\n",
    "\n",
    "#selecteer middelste XY punt\n",
    "def get_centermost_point(cluster):\n",
    "    centroid = (MultiPoint(cluster).centroid.x, MultiPoint(cluster).centroid.y)\n",
    "    centermost_point = min(cluster, key=lambda point: great_circle(point, centroid).m)\n",
    "    return tuple(centermost_point)\n",
    "centermost_points = clusters.map(get_centermost_point)\n",
    "\n",
    "# maak dataframe\n",
    "lats, lons = zip(*centermost_points)\n",
    "rep_points = pd.DataFrame({'t_longitude':lons, 't_latitude':lats})\n",
    "\n",
    "# print(pd.DataFrame(list(centermost_points))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stap 4: Maak cluster tabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Bereken gemiddelde snelheid en aantal XY punten per cluster\n",
    "kmu_per_cluster = Add_clusters.groupby('Cluster_new')['t_speed'].mean().reset_index(name='kmu_per_cluster')\n",
    "NoP_per_cluster = Add_clusters.groupby('Cluster_new')[\"Cluster_new\"].count().reset_index(name='NoP_per_cluster')\n",
    "distance_points_clusters = Add_clusters.groupby('Cluster_new')['distance_m'].mean().reset_index(name=\"distance_points_cluster\")\n",
    "NoP_kmu_per_cluster = pd.merge(kmu_per_cluster, NoP_per_cluster, on=[\"Cluster_new\"], how=\"left\")\n",
    "NoP_kmu_distance_per_cluster = pd.merge(NoP_kmu_per_cluster, distance_points_clusters, on=[\"Cluster_new\"], how=\"left\")\n",
    "\n",
    "## Voeg kolom toe die aangeeft of cluster een mogelijke stoplocatie is\n",
    "all_cluster_table = pd.merge(Add_clusters, NoP_kmu_distance_per_cluster, on=[\"Cluster_new\"], how=\"left\")\n",
    "\n",
    "stoplocation = []\n",
    "for stop in all_cluster_table[\"kmu_per_cluster\"]:\n",
    "    if stop < 2:\n",
    "        stoplocation.append(1)\n",
    "    else:\n",
    "        stoplocation.append(0)\n",
    "\n",
    "all_cluster_table[\"stoplocation\"] = stoplocation\n",
    "\n",
    "# Maak een cluster tabel met alleen de middelste punten van een cluster\n",
    "ID_centerpoint = all_cluster_table[[\"VgNr\", \"t_latitude\", \"t_longitude\", \"Lat_b\", \"Lon_b\", \"Cluster_new\", \"t_navstatus\", \"DateTime\", \"stoplocation\"]]\n",
    "ID_centerpoint_2 = pd.merge(rep_points, ID_centerpoint, on=[\"t_longitude\", \"t_latitude\"], how=\"left\")\n",
    "cluster_table = pd.merge(ID_centerpoint_2, NoP_kmu_distance_per_cluster, on=[\"Cluster_new\"], how=\"left\")\n",
    "\n",
    "# cluster tabel met alleen de stoplocaties\n",
    "ct_stoplocaties = cluster_table[cluster_table[\"stoplocation\"] ==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bereken accurancy\n",
    "\n",
    "nav_stops = []\n",
    "for nav in all_cluster_table[\"t_navstatus\"]:\n",
    "    if nav == 1:\n",
    "        nav_stops.append(1)\n",
    "    else:\n",
    "        nav_stops.append(0)\n",
    "\n",
    "all_cluster_table[\"nav_stops\"] = nav_stops\n",
    "\n",
    "y_score = all_cluster_table[\"nav_stops\"]\n",
    "y_test = all_cluster_table[\"stoplocation\"]\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "average_precision = average_precision_score(y_test, y_score)\n",
    "\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))\n",
    "\n",
    "print(pd.value_counts(all_cluster_table['t_navstatus'].values, sort=False))\n",
    "print(pd.value_counts(all_cluster_table['stoplocation'].values, sort=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cluster tabel op kaart\n",
    "\n",
    "# Zoek het middelste punt en zet de coordinaten in een lijst\n",
    "mid_location = ct_stoplocaties['t_latitude'].mean(), ct_stoplocaties['t_longitude'].mean()\n",
    "coords = ct_stoplocaties[[\"t_latitude\", \"t_longitude\"]].values.tolist()\n",
    "labels = ct_stoplocaties[\"VgNr\"].values.tolist()\n",
    "\n",
    "# Creëer een folium map met de coordinaten\n",
    "m = folium.Map(location=mid_location, zoom_start=8)\n",
    "for point in range(len(coords)):\n",
    "    popup = folium.Popup(labels[point], parse_html=True)\n",
    "    folium.Marker(coords[point], popup=popup).add_to(m)\n",
    "\n",
    "# Sla kaart op als HTML \n",
    "m.save('cluster_table_stops.html')\n",
    "\n",
    "# Weergeef de kaart (functie doet het niet op de DAT-omgeving)\n",
    "    #display(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colors = [\n",
    "#     'red',\n",
    "#     'blue',\n",
    "#     'gray',\n",
    "#     'darkred',\n",
    "#     'lightred',\n",
    "#     'orange',\n",
    "#     'beige',\n",
    "#     'green',\n",
    "#     'darkgreen',\n",
    "#     'lightgreen',\n",
    "#     'darkblue',\n",
    "#     'lightblue',\n",
    "#     'purple',\n",
    "#     'darkpurple',\n",
    "#     'pink',\n",
    "#     'cadetblue',\n",
    "#     'lightgray',\n",
    "#     'black'\n",
    "# ]\n",
    "\n",
    "all_cluster_table[\"t_navstatus\"] = all_cluster_table[\"t_navstatus\"].astype(int)\n",
    "\n",
    "colors = []\n",
    "for status in all_cluster_table[\"t_navstatus\"]:\n",
    "    if status == 0:\n",
    "        colors.append(\"green\")\n",
    "    elif status == 1:\n",
    "        colors.append(\"red\")\n",
    "    elif status == 5:\n",
    "        colors.append(\"orange\")\n",
    "    else:\n",
    "        color.append(\"white\")\n",
    "\n",
    "all_cluster_table[\"colors\"] = colors\n",
    "\n",
    "# Zoek het middelste punt en zet de coordinaten in een lijst\n",
    "mid_location = all_cluster_table['t_latitude'].mean(), all_cluster_table['t_longitude'].mean()\n",
    "coords = all_cluster_table[[\"t_latitude\", \"t_longitude\"]].values.tolist()\n",
    "# labels = all_cluster_table[\"VgNr\"].values.tolist()\n",
    "labels = \"ID:\"+all_cluster_table[\"VgNr\"].astype(str) +' '+all_cluster_table[\"t_name\"]\n",
    "colors = all_cluster_table[\"colors\"].values.tolist()\n",
    "\n",
    "# Creëer een folium map met de coordinaten\n",
    "m = folium.Map(location=mid_location, zoom_start=8)\n",
    "for point in range(len(coords)):\n",
    "    popup = folium.Popup(labels[point], parse_html=True)\n",
    "    folium.Marker(coords[point], popup=popup, icon=folium.Icon(color=colors[point])).add_to(m)\n",
    "\n",
    "# Sla kaart op als HTML \n",
    "m.save('cluster_table_stops_color.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing Pandas \n",
    "# https://medium.com/@ozan/interactive-plots-with-plotly-and-cufflinks-on-pandas-dataframes-af6f86f62d94\n",
    "import pandas as pd\n",
    "#importing plotly and cufflinks in offline mode\n",
    "import cufflinks as cf\n",
    "import plotly.offline\n",
    "cf.go_offline()\n",
    "cf.set_config_file(offline=False, world_readable=True)\n",
    "\n",
    "#we will get help from pivot tables to get Fare values in different columns for each class.\n",
    "all_cluster_table[['t_speed', 'Cluster_new']].pivot(columns='Cluster_new', values='t_speed').iplot(kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Maak boxplot\n",
    "# %matplotlib notebook\n",
    "\n",
    "# d_ata = {\n",
    "#             \"speed\": Add_clusters[\"t_speed\"],\n",
    "#             \"cluster_nummer\": Add_clusters[\"Cluster_new\"],\n",
    "# }\n",
    "\n",
    "# d_ata = pd.DataFrame(d_ata)\n",
    "\n",
    "# d_ata[[\"speed\", \"cluster_nummer\"]].boxplot( by=\"cluster_nummer\", return_type=\"axes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from sklearn.metrics import average_precision_score \n",
    "# from sklearn.metrics import precision_score\n",
    "\n",
    "# #Variabelen invoeren DBScan en schalen\n",
    "# df = pd.read_csv(\"AIS_preprocessing.csv\")\n",
    "# coords_speed = np.asarray(df[['t_latitude', 't_longitude', \"t_speed\"]])\n",
    "# coords = preprocessing.scale(coords_speed)\n",
    "# eps_samples = u_waarden[[\"x\", \"y\"]]\n",
    "\n",
    "# def dbs(df, coords, eps, min_samples):\n",
    "#     model = DBSCAN(eps=eps, min_samples=min_samples, algorithm=\"auto\").fit(coords)\n",
    "#     cluster_labels = model.labels_\n",
    "#     num_clusters = len(set(cluster_labels))\n",
    "#     df[\"cluster\"] = cluster_labels\n",
    "       \n",
    "#     #Vinden van verschillen in kolom cluster_x\n",
    "#     df[\"Check_overlap\"] = df['cluster'].diff()\n",
    "#     #Clusters nieuwe clusterwaarden geven als er een verschil is met vorige rij in kolom Check_overlap.\n",
    "#     #Let op nieuwe clusternummers komen niet overeen met de oude clusternummers!\n",
    "#     df['Cluster_new']= (df['Check_overlap'] != 0).astype(int).cumsum()\n",
    "\n",
    "#     # De oorspronkelijke cluster -1 (=ruis) overnemen als None waarden in kolom Cluster_new\n",
    "#     df['Cluster_new'] = np.where(df['cluster'] == -1, -1, (df['Cluster_new']))\n",
    "\n",
    "#     # Verwerken van de modelresultaten tot nieuwe clusters\n",
    "#     result_total = df.sort_values(['Cluster_new'])\n",
    "\n",
    "#     df_vgnr = result_total.groupby('Cluster_new')['VgNr'].agg(['min','max']).rename(columns={'min': 'vgnr_min', 'max': 'vgnr_max'}).reset_index()\n",
    "#     df_dt = result_total.groupby('Cluster_new')['DateTime'].agg(['min','max']).rename(columns={'min': 'dt_min', 'max': 'dt_max'}).reset_index()\n",
    "#     df_concat = pd.merge(df_dt, df_vgnr, left_on='Cluster_new', right_on='Cluster_new')\n",
    "#     df[\"start\"] = df.DateTime.isin(df_concat.dt_min).astype(int)\n",
    "#     df[\"end\"] = df.DateTime.isin(df_concat.dt_max).astype(int)\n",
    "#     df[\"start\"] = df['start'].replace(0, np.nan)\n",
    "#     df[\"end\"] = df['end'].replace(0, np.nan)\n",
    "#     df.sort_values(['DateTime'], inplace=True)\n",
    "    \n",
    "#     ##Bereken gemiddelde snelheid en aantal XY punten per cluster\n",
    "#     kmu_per_cluster = df.groupby('Cluster_new')['t_speed'].mean().reset_index(name='kmu_per_cluster')\n",
    "#     NoP_per_cluster = df.groupby('Cluster_new')[\"Cluster_new\"].count().reset_index(name='NoP_per_cluster')\n",
    "#     distance_points_clusters = df.groupby('Cluster_new')['distance_m'].mean().reset_index(name=\"distance_points_cluster\")\n",
    "#     NoP_kmu_per_cluster = pd.merge(kmu_per_cluster, NoP_per_cluster, on=[\"Cluster_new\"], how=\"left\")\n",
    "#     NoP_kmu_distance_per_cluster = pd.merge(NoP_kmu_per_cluster, distance_points_clusters, on=[\"Cluster_new\"], how=\"left\")\n",
    "\n",
    "#     ## Voeg kolom toe die aangeeft of cluster een mogelijke stoplocatie is\n",
    "#     all_cluster_table = pd.merge(df, NoP_kmu_distance_per_cluster, on=[\"Cluster_new\"], how=\"left\")\n",
    "\n",
    "#     stoplocation = []\n",
    "#     for stop in all_cluster_table[\"kmu_per_cluster\"]:\n",
    "#         if stop < 2:\n",
    "#             stoplocation.append(1)\n",
    "#         else:\n",
    "#             stoplocation.append(0)\n",
    "\n",
    "#     all_cluster_table[\"stoplocation\"] = stoplocation\n",
    "    \n",
    "#     #Voeg kolom toe die aangeeft wat een mogelijke stoplocatie is via navigatiestatus\n",
    "#     nav_stops = []\n",
    "#     for nav in all_cluster_table[\"t_navstatus\"]:\n",
    "#         if nav == 1:\n",
    "#             nav_stops.append(1)\n",
    "#         else:\n",
    "#             nav_stops.append(0)\n",
    "\n",
    "#     all_cluster_table[\"nav_stops\"] = nav_stops\n",
    "\n",
    "#     #precision van clusteren\n",
    "#     y_true = all_cluster_table[\"nav_stops\"]\n",
    "#     y_pred = all_cluster_table[\"stoplocation\"]\n",
    "\n",
    "#     average_precision = precision_score(y_true, y_pred, average='binary')\n",
    "#     count_nav = pd.value_counts(all_cluster_table['nav_stops'].values, sort=False)\n",
    "#     count_stop = pd.value_counts(all_cluster_table['stoplocation'].values, sort=False)  \n",
    "    \n",
    "#     return (eps, min_samples, num_clusters, average_precision, count_nav, count_stop)\n",
    "\n",
    "# #Voer dbscan uit + precision voor elke hoogste u waarden per min_samples\n",
    "# output_list_eps = []\n",
    "# for index, row in eps_samples.iterrows():\n",
    "#     output_eps = dbs(df=df, coords=coords, eps=row[\"x\"], min_samples=row[\"y\"])\n",
    "#     output_list_eps.append(output_eps)\n",
    "\n",
    "# #Uitkomst in dataframe + print dataframa\n",
    "# output_list_eps_df = pd.DataFrame(output_list_eps, columns = [\"eps\", \"min_samples\", \"aantal_cluster\", \"percision\", \"count_nav\", \"count_stop\"])\n",
    "# output_list_eps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # speed vs cluster\n",
    "# %matplotlib notebook\n",
    "\n",
    "# y = d_ata[\"speed\"]\n",
    "# x = d_ata[\"cluster_nummer\"]\n",
    "\n",
    "# sns.set(style=\"darkgrid\")\n",
    "# sns.lineplot(x=x, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ct = cluster_table_no_1[cluster_table_no_1[\"kmu_per_cluster\"] <=2]\n",
    "# ct = cluster_table\n",
    "\n",
    "# # %matplotlib notebook\n",
    "\n",
    "# y = ct[\"kmu_per_cluster\"]\n",
    "# x = ct[\"Cluster_new\"]\n",
    "\n",
    "# sns.set(style=\"darkgrid\")\n",
    "# sns.lineplot(x=x, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib notebook \n",
    "# # a = cluster_table_no_1[\"Cluster_new\"]\n",
    "# # b = cluster_table_no_1[\"kmu_per_cluster\"]\n",
    "\n",
    "# a = ct[\"Cluster_new\"]\n",
    "# b = ct[\"kmu_per_cluster\"]\n",
    "# # speed vs cluster\n",
    "# sns.set(style=\"darkgrid\")\n",
    "# sns.lineplot(x=a, y=b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # table: \n",
    "#     - mmsi \n",
    "#     - naam \n",
    "#     - shiptype\n",
    "#     - t_starttime \n",
    "#     - destination\n",
    "#     - tijd in dataset \n",
    "#     - aantal berichten \n",
    "#     - gemiddelde tijd tussen berichten \n",
    "#     - gemiddelde snelheid\n",
    "#     - aantal punten at anchor / aantal punten niet at anchor\n",
    "   \n",
    "# Heatmap van snelheden vs tijd\n",
    "# Heatmap van aantal berichten vs tijd\n",
    "# Heatmap navstatus vs tijd\n",
    "# Heatmap snelheid vs tijd\n",
    "# heatmap aantal berichten vs navstatus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt, mpld3\n",
    "\n",
    "\n",
    "# x = Add_clusters[\"t_speed\"]\n",
    "# y = Add_clusters[\"cluster_x\"]\n",
    "\n",
    "# bp = plt.boxplot(x=x, labels=y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # p = BoxPlot(values=y, label=x,\n",
    "# #             title=\"MPG Summary (grouped by CYL)\")\n",
    "\n",
    "# # output_file(\"boxplot.html\")\n",
    "\n",
    "# # show(p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set(style=\"ticks\", palette=\"pastel\")\n",
    "\n",
    "# # Load the example tips dataset\n",
    "# y = Add_clusters[\"t_speed\"]\n",
    "# x = Add_clusters[\"cluster_x\"]\n",
    "\n",
    "# # # Draw a nested boxplot to show bills by day and time\n",
    "# sns.boxplot(x=x, y=y,)\n",
    "# sns.despine(offset=10, trim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functie maken om tabel te creëren met resultaten DBScan, u waarden en gemiddelde snelheden\n",
    "# def gemiddelde_distance_per_eps(df, coords, eps, min_samples, distance_column=\"distance_m\"):\n",
    "#     model = DBSCAN(eps=eps, min_samples=min_samples, algorithm=\"auto\").fit(coords)\n",
    "#     cluster_labels = model.labels_\n",
    "#     num_clusters = len(set(cluster_labels))\n",
    "#     df[\"cluster\"] = cluster_labels\n",
    "#     clusters = df.distance_m[df[\"cluster\"] > -1]   \n",
    "#     ruis =df.distance_m[df[\"cluster\"] == -1]\n",
    "#     u, prob = mannwhitneyu(clusters, ruis)\n",
    "#     distance_per_cluster = df.groupby('cluster')[\"distance_m\"].mean().reset_index(name='distance_per_cluster')\n",
    "#     mean_distance = distance_per_cluster[\"distance_per_cluster\"].mean()\n",
    "#     return (eps, min_samples, num_clusters, mean_distance, u)\n",
    "\n",
    "# # Bovenstaande functie uitvoeren voor 500 verschillende epsilons en 7 verschillende MinPoints\n",
    "# output_list = []\n",
    "# for epsilon in np.linspace(0.001, 0.05, 50):\n",
    "#     for min_samples in range(1, 8, 1):\n",
    "#         output = gemiddelde_distance_per_eps(df=df, coords=coords, eps=epsilon, min_samples=min_samples)\n",
    "#         output_list.append(output)\n",
    "\n",
    "# # Resultaten functie naar tabel\n",
    "# output_df = pd.DataFrame(output_list, columns = [\"eps\", \"min_samples\", \"NoP_cluster\", \"mean_distance\", \"MannWhitney_U\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_04_01 = df[(df[['Day']] == 1).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --> aantal berichten\n",
    "# --> longest / smallest / mean time gap between messages\n",
    "# --> van waar naar waar\n",
    "# --> van hoelang hebben we data\n",
    "# --> gemiddelde snelheid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = [];\n",
    "# with open(\"AIS_week.csv\", newline='') as csvfile:\n",
    "#     csvreader = csv.reader(csvfile);\n",
    "#     for index, row in enumerate(csvreader):\n",
    "#         if row[5] == \"477050500\":\n",
    "#             data.append(tuple(row));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = pd.DataFrame(data)\n",
    "# d.to_csv(\"MMSI_477050500.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"MMSI_477050500.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename1 = '/data/candyreebroek/ID_lab/Schepen/Data/AIS_data_week.csv.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = [];\n",
    "# with open(\"AIS_week.csv\", newline='') as csvfile:\n",
    "#     csvreader = csv.reader(csvfile);\n",
    "# #     for i in tnrange(100, desc=\"loop\"):\n",
    "# #         sleep(0.01)\n",
    "#     for index, row in enumerate(csvreader):\n",
    "# #         if index == 1000000:\n",
    "# #             break;\n",
    "#         if row[5] == \"477050500\":\n",
    "#             data.append(tuple(row));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = [];\n",
    "# with open(\"AIS_week.csv\", newline='') as csvfile:\n",
    "#     csvreader = csv.reader(csvfile);\n",
    "#     values = range(3);\n",
    "# #     with tqdm(total=len(values)) as pbar:\n",
    "# #         for i in values:\n",
    "# #             pbar.write('processed: %d' %i);\n",
    "# #             pbar.update(1);\n",
    "# #             sleep(1);\n",
    "#         for index, row in enumerate(csvreader):\n",
    "#             if index == 100000000:\n",
    "#                 break;\n",
    "#             if row[6] ==\"9605243\":\n",
    "#                 data.append(tuple(row));\n",
    "        \n",
    "\n",
    "#     for i in tqdm:\n",
    "#         time.sleep(0.25);\n",
    "#         pbar.set_description(\"Processing %s\" % char);\n",
    "#         time.sleep(0.01);\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = [];\n",
    "# with open(\"AIS_week.csv\", newline='') as csvfile:\n",
    "#     csvreader = csv.reader(csvfile);\n",
    "#     for i in tnrange(1, desc='1st loop'):\n",
    "#         for j in tqdm_notebook(range(100), desc='2nd loop'):\n",
    "#             sleep(0.01);\n",
    "#         for index, row in enumerate(csvreader):\n",
    "#             if index == 1000000:\n",
    "#                 break;\n",
    "#             if row[6] !=\"\":\n",
    "#                 data.append(tuple(row));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = [];\n",
    "# with open(\"AIS_week.csv\", newline='') as csvfile:\n",
    "#     csvreader = csv.reader(csvfile);\n",
    "# #     next(csvreader); # Sla header over.\n",
    "# #     for row in tqdm(csvreader):\n",
    "#     for index, row in enumerate(csvreader):\n",
    "#         if index == 3000000:\n",
    "#             break;\n",
    "#         if row[6] !=\"\": \n",
    "#             data.append(tuple(row));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # 1.000.000 is haalbaar\n",
    "\n",
    "\n",
    "# df = pd.read_csv(filename1, nrows=2000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Selecteer meest actieve schip\n",
    "# df[\"count_name\"] = df.groupby(\"t_mmsi\")[\"t_mmsi\"].transform(\"count\")\n",
    "\n",
    "# df.sort_values([\"count_name\"], ascending=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.memory_usage().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# for df in pd.read_csv(filename1, iterator=True, chunksize=1e8):\n",
    "#     # Creation of a new dataframe df_new without the less relevant columns\n",
    "#     systemID = df.iloc[:,0:1]\n",
    "#     name_lat_long = df.iloc[:,6:9]\n",
    "#     imo = df.iloc[:,33:34]\n",
    "#     t_init = df.iloc[:,1:2]\n",
    "#     t_update = df.iloc[:,2:3]\n",
    "#     mmsi = df.iloc[:,5:6]\n",
    "#     ves = df.iloc[:,40:41]\n",
    "#     des = df.iloc[:,30:31]\n",
    "#     speed = df.iloc[:,20:21]\n",
    "#     heading = df.iloc[:,21:22]\n",
    "#     length = df.iloc[:,11:12]\n",
    "#     navstatus = df.iloc[:,14:15]\n",
    "\n",
    "#     df_new = pd.concat([systemID, name_lat_long, imo, mmsi, ves, des, speed, heading, length, navstatus ,t_init, t_update, ],axis=1)\n",
    "#     df_new.columns = ['SystemID', 'Name', 'Lat', 'Lon', 'IMO', 'MMSI', 'Schiptype', 'Destination', 'Speed', 'Heading', 'Length', \"NavStatus\", 'Starttime', 'Updatetime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (taxiroot)",
   "language": "python",
   "name": "taxiroot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
